# -*- coding: utf-8 -*-
"""ocr_gpu.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GoxqQnOX7AxcSeCmPUA48zsGreoHf71G
"""

!nvidia-smi

import paddle
print(paddle.device.get_device())

!pip install easyocr

import PIL
import gradio
print("Pillow:", PIL.__version__)
print("Gradio:", gradio.__version__)

!pip uninstall -y pillow paddlepaddle
!pip install pillow==11.3.0 paddlepaddle-gpu paddleocr opencv-python pdf2image

!pip uninstall -y gradio #not required unless creating UI

!pip uninstall -y numpy opencv-python opencv-python-headless packaging
!pip install \
numpy==1.26.4 \
opencv-python-headless==4.9.0.80 \
packaging==24.2 \
pillow==11.3.0

import numpy, cv2, packaging
print("NumPy:", numpy.__version__)
print("OpenCV:", cv2.__version__)
print("Packaging:", packaging.__version__)

!pip install paddlepaddle-gpu paddleocr pdf2image

import os

BASE = "/content/ocr_gpu"

FOLDERS = [
    "input/images",
    "input/pdf",
    "output/deskewed",
    "output/rotated",
    "output/preprocessed",
    "output/text"
]

for f in FOLDERS:
    os.makedirs(os.path.join(BASE, f), exist_ok=True)

print("Folders ready")

from google.colab import files
files.upload()

import shutil, os

for f in os.listdir("/content"):
    if f.lower().endswith((".jpg", ".png", ".jpeg", ".pdf")):
        shutil.move(f, f"{BASE}/input/images")

from google.colab import files
files.upload()

import os, shutil

INPUT_DIR = "/content/ocr_gpu/input"

for f in os.listdir("/content"):
    if f.lower().endswith((".jpg", ".jpeg", ".png", ".pdf")):
        shutil.move(f"/content/{f}", f"{INPUT_DIR}/{f}")

print("Files moved to input folder")

!unzip samples.zip -d /content/ocr_gpu/input

!sudo apt-get install -y python3.10 python3.10-distutils

import sys
print(sys.version)

!pip uninstall -y paddleocr paddlepaddle paddlepaddle-gpu paddlex

!pip install numpy==1.26.4 pillow==11.3.0 opencv-python-headless==4.9.0.80 pymupdf
!pip install paddlepaddle-gpu==2.6.1
!pip install paddleocr==2.7.3

import paddle
print("Paddle version:", paddle.__version__)
print("Device:", paddle.device.get_device())

import os
os.environ["DISABLE_MODEL_SOURCE_CHECK"] = "True"

from paddleocr import PaddleOCR

ocr = PaddleOCR(
    lang="en",
    use_textline_orientation=True,
    show_log=False
)

print("✓ PaddleOCR ready")

DESKEW_DIR = f"/content/ocr_gpu/output/deskewed"
ROTATED_DIR = f"/content/ocr_gpu/output/rotated"
PREP_DIR = f"/content/ocr_gpu/output/preprocessed"

for d in [DESKEW_DIR, ROTATED_DIR, PREP_DIR]:
    os.makedirs(d, exist_ok=True)

# =========================================================
# GPU BATCH OCR WITH TIME TRACKING + DOC TYPE DETECTION
# =========================================================

import os
import cv2
import numpy as np
import re
import time
import fitz  # PyMuPDF
from paddleocr import PaddleOCR
from PIL import Image, ImageEnhance
from datetime import timedelta

# ---------------- PATHS ----------------
BASE_DIR = "/content/ocr_gpu"

INPUT_DIR = f"{BASE_DIR}/input/samples"
TEMP_DIR = f"{BASE_DIR}/temp"

DESKEW_DIR = f"{BASE_DIR}/output/deskewed"
PREP_DIR = f"{BASE_DIR}/output/preprocessed"
TEXT_DIR = f"{BASE_DIR}/output/text/samples"

for d in [INPUT_DIR, TEMP_DIR, DESKEW_DIR, PREP_DIR, TEXT_DIR]:
    os.makedirs(d, exist_ok=True)

# ---------------- OCR INIT ----------------
import os as _os
_os.environ["DISABLE_MODEL_SOURCE_CHECK"] = "True"

ocr = PaddleOCR(
    lang="en",
    use_textline_orientation=True,
    show_log=False
)

print("✓ PaddleOCR initialized")

# ---------------- PDF → IMAGE ----------------
def pdf_to_images(pdf_path):
    images = []
    pdf = fitz.open(pdf_path)

    for i in range(len(pdf)):
        page = pdf[i]
        pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

        out_path = os.path.join(
            TEMP_DIR,
            f"{os.path.splitext(os.path.basename(pdf_path))[0]}_page_{i+1}.jpg"
        )
        img.save(out_path)
        images.append(out_path)

    pdf.close()
    return images

# ---------------- DESKEW ----------------
def deskew(image_path):
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)

    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)
    if lines is None:
        return image_path

    angles = []
    for rho, theta in lines[:, 0]:
        angle = np.degrees(theta) - 90
        if -45 < angle < 45:
            angles.append(angle)

    if not angles:
        return image_path

    angle = np.median(angles)
    if abs(angle) < 0.5:
        return image_path

    h, w = img.shape[:2]
    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)
    corrected = cv2.warpAffine(
        img, M, (w, h),
        flags=cv2.INTER_CUBIC,
        borderMode=cv2.BORDER_REPLICATE
    )

    name = os.path.splitext(os.path.basename(image_path))[0]
    out = os.path.join(DESKEW_DIR, f"{name}_deskew.jpg")
    cv2.imwrite(out, corrected)
    return out

# ---------------- PREPROCESS ----------------
def preprocess(image_path):
    img = cv2.imread(image_path)

    pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    w, h = pil.size
    pil = pil.resize((w*2, h*2), Image.LANCZOS)

    pil = ImageEnhance.Sharpness(pil).enhance(1.6)
    pil = ImageEnhance.Contrast(pil).enhance(1.4)

    img = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    clahe = cv2.createCLAHE(2.5, (8, 8))
    final = clahe.apply(gray)

    name = os.path.splitext(os.path.basename(image_path))[0]
    out = os.path.join(PREP_DIR, f"{name}_prep.jpg")
    cv2.imwrite(out, final)
    return out

# ---------------- OCR ----------------
def extract_text(image_path):
    result = ocr.ocr(image_path)
    if not result or not result[0]:
        return ""
    return "\n".join([line[1][0] for line in result[0]])

# ---------------- TEXT POSTPROCESS (FIXED) ----------------
def clean_text(text):
    """
    1. Preserve OCR line breaks
    2. Further split long lines into sentences
    """
    if not text:
        return ""

    lines = []
    for raw_line in text.split("\n"):
        raw_line = raw_line.strip()
        if not raw_line:
            continue

        # Split sentences inside each OCR line
        sentences = re.split(r'(?<=[.!?])\s+', raw_line)
        for s in sentences:
            s = s.strip()
            if len(s) > 1:
                lines.append(s)

    return "\n".join(lines)

# ---------------- DOCUMENT TYPE DETECTION ----------------
def detect_document_type(text):
    t = text.lower()

    if re.search(r'\b\d{4}\s?\d{4}\s?\d{4}\b', t):
        return "Aadhaar"
    if re.search(r'\b[a-z]{5}\d{4}[a-z]\b', t):
        return "PAN"
    if "driving licence" in t or "dl no" in t:
        return "Driving Licence"
    if "passport" in t:
        return "Passport"

    return "Unknown"

# ---------------- MAIN PIPELINE ----------------
start_time = time.time()
total_files = 0

files = os.listdir(INPUT_DIR)

for file in files:
    file_path = os.path.join(INPUT_DIR, file)
    print(f"\nProcessing: {file}")

    images = []

    if file.lower().endswith(".pdf"):
        images = pdf_to_images(file_path)
    elif file.lower().endswith((".jpg", ".jpeg", ".png")):
        images = [file_path]
    else:
        print("Skipped unsupported file")
        continue

    for img in images:
        total_files += 1

        d = deskew(img)
        p = preprocess(d)
        raw_text = extract_text(p)
        final_text = clean_text(raw_text)
        doc_type = detect_document_type(final_text)

        name = os.path.splitext(os.path.basename(img))[0]
        out_path = os.path.join(TEXT_DIR, f"{name}.txt")

        with open(out_path, "w", encoding="utf-8") as f:
            f.write(f"Document Type: {doc_type}\n")
            f.write("="*40 + "\n")
            f.write(final_text)

        print(f"✓ Saved: {out_path} | Type: {doc_type}")

# ---------------- TIME REPORT ----------------
end_time = time.time()
elapsed = timedelta(seconds=int(end_time - start_time))

print("\n================ SUMMARY ================")
print(f"Total files processed : {total_files}")
print(f"Total time taken      : {elapsed}")
print("========================================")

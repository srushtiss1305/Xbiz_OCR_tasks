# -*- coding: utf-8 -*-
"""ocr_gpu_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YlwxSDNlcDfCRAqj5G0kT0DXZ4WaFFwM
"""

!nvidia-smi

!pip uninstall -y pillow paddlepaddle
!pip install pillow==11.3.0 paddlepaddle-gpu paddleocr opencv-python pdf2image

!pip uninstall -y numpy opencv-python opencv-python-headless packaging
!pip install \
numpy==1.26.4 \
opencv-python-headless==4.9.0.80 \
packaging==24.2 \
pillow==11.3.0

import numpy, cv2, packaging
print("NumPy:", numpy.__version__)
print("OpenCV:", cv2.__version__)
print("Packaging:", packaging.__version__)

import os

BASE = "/content/ocr_gpu"

FOLDERS = [
    "input/images",
    "input/pdf",
    "output/deskewed",
    "output/rotated",
    "output/preprocessed",
    "output/text"
]

for f in FOLDERS:
    os.makedirs(os.path.join(BASE, f), exist_ok=True)

print("Folders ready")

from google.colab import files
files.upload()
!unzip samples.zip -d /content/ocr_gpu/input

!sudo apt-get install -y python3.10 python3.10-distutils

!pip install numpy==1.26.4 pillow==11.3.0 opencv-python-headless==4.9.0.80 pymupdf
!pip install paddlepaddle-gpu==2.6.1
!pip install paddleocr==2.7.3

import sys
print(sys.version)

# =========================================================
# GPU OCR WITH TRUE LAYOUT PRESERVATION (IMAGE / PDF)
# =========================================================

import os
import cv2
import numpy as np
import re
import time
import fitz  # PyMuPDF
from paddleocr import PaddleOCR
from PIL import Image, ImageEnhance
from datetime import timedelta

# ---------------- PATHS ----------------
BASE_DIR = "/content/ocr_gpu"

INPUT_DIR = f"{BASE_DIR}/input/samples"
TEMP_DIR = f"{BASE_DIR}/temp"

DESKEW_DIR = f"{BASE_DIR}/output/deskewed"
PREP_DIR   = f"{BASE_DIR}/output/preprocessed"
TEXT_DIR   = f"{BASE_DIR}/output/text"

for d in [INPUT_DIR, TEMP_DIR, DESKEW_DIR, PREP_DIR, TEXT_DIR]:
    os.makedirs(d, exist_ok=True)

# ---------------- OCR INIT ----------------
os.environ["DISABLE_MODEL_SOURCE_CHECK"] = "True"

ocr = PaddleOCR(
    lang="en",
    use_textline_orientation=True,
    show_log=False,
    use_gpu=True
)

print("✓ PaddleOCR initialized (GPU)")

# ---------------- PDF → IMAGE ----------------
def pdf_to_images(pdf_path):
    images = []
    pdf = fitz.open(pdf_path)

    for i, page in enumerate(pdf):
        pix = page.get_pixmap(matrix=fitz.Matrix(300/72, 300/72))
        img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

        out_path = os.path.join(
            TEMP_DIR,
            f"{os.path.splitext(os.path.basename(pdf_path))[0]}_page_{i+1}.jpg"
        )
        img.save(out_path)
        images.append(out_path)

    pdf.close()
    return images

# ---------------- DESKEW ----------------
def deskew(image_path):
    img = cv2.imread(image_path)
    if img is None:
        return image_path

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    edges = cv2.Canny(gray, 50, 150)

    lines = cv2.HoughLines(edges, 1, np.pi / 180, 200)
    if lines is None:
        return image_path

    angles = []
    for rho, theta in lines[:, 0]:
        angle = np.degrees(theta) - 90
        if -45 < angle < 45:
            angles.append(angle)

    if not angles:
        return image_path

    angle = np.median(angles)
    if abs(angle) < 0.5:
        return image_path

    h, w = img.shape[:2]
    M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)
    corrected = cv2.warpAffine(
        img, M, (w, h),
        flags=cv2.INTER_CUBIC,
        borderMode=cv2.BORDER_REPLICATE
    )

    out = os.path.join(DESKEW_DIR, os.path.basename(image_path))
    cv2.imwrite(out, corrected)
    return out

# ---------------- PREPROCESS ----------------
def preprocess(image_path):
    img = cv2.imread(image_path)
    if img is None:
        return image_path

    pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    w, h = pil.size

    # Controlled upscale (safe)
    scale = min(2.0, 3000 / max(w, h))
    pil = pil.resize((int(w * scale), int(h * scale)), Image.LANCZOS)

    pil = ImageEnhance.Sharpness(pil).enhance(1.4)
    pil = ImageEnhance.Contrast(pil).enhance(1.3)

    img = cv2.cvtColor(np.array(pil), cv2.COLOR_RGB2BGR)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    clahe = cv2.createCLAHE(2.0, (8, 8))
    final = clahe.apply(gray)

    out = os.path.join(PREP_DIR, os.path.basename(image_path))
    cv2.imwrite(out, final)
    return out

# ---------------- OCR WITH BOXES ----------------
def extract_text_with_boxes(image_path):
    result = ocr.ocr(image_path, cls=True)
    if not result or not result[0]:
        return []

    lines = []
    for line in result[0]:
        box = line[0]
        text = line[1][0]
        lines.append((box, text))

    return lines

# ---------------- TRUE LAYOUT RECONSTRUCTION ----------------
def rebuild_layout(ocr_lines, y_threshold=18, x_threshold=40):
    if not ocr_lines:
        return ""

    ocr_lines.sort(key=lambda x: min(pt[1] for pt in x[0]))

    rows = []

    for box, text in ocr_lines:
        y_center = np.mean([pt[1] for pt in box])
        x_left = min(pt[0] for pt in box)

        placed = False
        for row in rows:
            if abs(row["y"] - y_center) <= y_threshold:
                row["items"].append((x_left, text))
                placed = True
                break

        if not placed:
            rows.append({"y": y_center, "items": [(x_left, text)]})

    for row in rows:
        row["items"].sort(key=lambda x: x[0])

    merged_rows = []
    prev_row = None

    for row in rows:
        if prev_row is None:
            merged_rows.append(row)
            prev_row = row
            continue

        curr_cols = row["items"]
        prev_cols = prev_row["items"]

        same_first_col = abs(curr_cols[0][0] - prev_cols[0][0]) <= x_threshold
        curr_only_first_col = len(curr_cols) == 1
        prev_has_multiple_cols = len(prev_cols) > 1

        if same_first_col and curr_only_first_col and prev_has_multiple_cols:
            prev_cols[0] = (
                prev_cols[0][0],
                prev_cols[0][1] + " " + curr_cols[0][1]
            )
        else:
            merged_rows.append(row)
            prev_row = row

    final_lines = []
    for row in merged_rows:
        line = "   ".join(text for _, text in row["items"])
        final_lines.append(line.strip())

    return "\n".join(final_lines)

# ---------------- DOCUMENT TYPE DETECTION ----------------
def detect_document_type(text):
    t = text.lower()

    if re.search(r'\b\d{4}\s?\d{4}\s?\d{4}\b', t):
        return "Aadhaar"
    if re.search(r'\b[a-z]{5}\d{4}[a-z]\b', t):
        return "PAN"
    if "driving licence" in t or "dl no" in t:
        return "Driving Licence"
    if "passport" in t:
        return "Passport"
    if "bank" in t or "credit" in t:
        return "Bank Details"
    if "electricity" in t:
        return "Electricity Bill"

    return "Unknown"

# ---------------- MAIN PIPELINE ----------------
start_time = time.time()
total_files = 0

files = os.listdir(INPUT_DIR)
assert files, "❌ INPUT FOLDER IS EMPTY"

for file in files:
    file_path = os.path.join(INPUT_DIR, file)
    print(f"\nProcessing: {file}")

    if file.lower().endswith(".pdf"):
        images = pdf_to_images(file_path)
    elif file.lower().endswith((".jpg", ".jpeg", ".png")):
        images = [file_path]
    else:
        print("Skipped unsupported file")
        continue

    for img in images:
        total_files += 1

        d = deskew(img)
        p = preprocess(d)

        ocr_lines = extract_text_with_boxes(p)
        final_text = rebuild_layout(ocr_lines)
        doc_type = detect_document_type(final_text)

        name = os.path.splitext(os.path.basename(img))[0]
        out_path = os.path.join(TEXT_DIR, f"{name}.txt")

        with open(out_path, "w", encoding="utf-8") as f:
            f.write(f"Document Type: {doc_type}\n")
            f.write("=" * 50 + "\n")
            f.write(final_text)

        print(f"✓ Saved: {out_path} | Type: {doc_type}")

# ---------------- TIME REPORT ----------------
elapsed = timedelta(seconds=int(time.time() - start_time))

print("\n================ SUMMARY ================")
print(f"Total files processed : {total_files}")
print(f"Total time taken      : {elapsed}")
print("========================================")